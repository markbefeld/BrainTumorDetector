{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2926ef92-3451-4a80-87b4-576b61593646",
   "metadata": {},
   "source": [
    "# Brain Tumor Detection: A Convolutional Neural Network Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab35d7-d2ab-4029-b783-25156cbb2cda",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5bacf87-6ab8-4d03-a285-2ad80cabc9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bea18b-9bd6-4b8f-a834-cce6492c5892",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c182e9-9a09-425d-9143-d95e8c527537",
   "metadata": {},
   "source": [
    "Can a CNN be used to predict the presence of a brain tumor in MRI brain scans more accurately than a baseline score of 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbe480-5c7c-4233-8456-01339fad9ac5",
   "metadata": {},
   "source": [
    "## Data Processing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beb3a7b-f599-41fa-93f9-2b5891fe49f0",
   "metadata": {},
   "source": [
    "Because this data is exclusively images, a visual inspection was done to ensure the integrity of the files. Other than that any files that were corrupt or unable to be parsed into 2d arrays would have thrown an exception in the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7bd0b6-c334-4c7d-be84-2d92dd550fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "#Process Images for Tumors\n",
    "\n",
    "tumor_array = []\n",
    "\n",
    "tumor_path = 'Data/yes/'\n",
    "\n",
    "#Convert images into arrays\n",
    "for file in os.listdir(tumor_path):\n",
    "    try:\n",
    "#Resize all images for data homogeniety \n",
    "        tumor = load_img(tumor_path + file, target_size=(256, 256))\n",
    "        tumor_arr = img_to_array(tumor) / 255\n",
    "        tumor_array.append(tumor_arr)\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "\n",
    "print(f'{len(tumor_array)} pictures converted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be89a40-1467-476a-9f38-2155f4ea0d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "#Process Images for Healthy\n",
    "\n",
    "healthy_array = []\n",
    "\n",
    "healthy_path = 'Data/no/'\n",
    "\n",
    "#Convert images into arrays\n",
    "for file in os.listdir(healthy_path):\n",
    "    try:\n",
    "#Resize all images for data homogeniety         \n",
    "        healthy = load_img(healthy_path + file, target_size=(256, 256))\n",
    "        healthy_arr = img_to_array(healthy) / 255\n",
    "        healthy_array.append(healthy_arr)\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "\n",
    "print(f'{len(healthy_array)} pictures converted.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8244875-f1c5-400e-afb8-36d565e2291a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (3000, 256, 256, 3)\n",
      "y shape: (3000,)\n"
     ]
    }
   ],
   "source": [
    "#create arrays of arrays to house binary classifications\n",
    "\n",
    "X = tumor_array + healthy_array\n",
    "\n",
    "X_arr = np.array(X)\n",
    "print(f'X shape: {X_arr.shape}')\n",
    "\n",
    "# 1 for healthy, 0 for tumor\n",
    "y = [1] * 1500 + [0] * 1500\n",
    "# convert to array and check shape\n",
    "y = np.array(y)\n",
    "print(f'y shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78897c6-a0bd-417b-aa12-8b8078c05ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf24325a-dfb2-4024-858c-74b407160282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae991bdc-6b48-4e76-b304-0bade8e023c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d17273ee-70dd-41db-9ba7-36f0e5992265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c776b870-21ac-4b62-a805-85dd681cc996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2250,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb244d8-a239-4021-9d15-2d99f6197622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 256, 256, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ca74c2d-533e-4116-a811-3254a6518cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1802c758-43a8-4317-a0a9-2e96f701f031",
   "metadata": {},
   "source": [
    "## Model Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ef62fa8-b353-4227-b02b-28b5d0a9fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a sequential Neural Net utilizing relu activation layers and a sigmoid output layer \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu', input_shape = (256, 256, 3)))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Add another:\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "#Callback\n",
    "early_stop = EarlyStopping(monitor= 'val_loss', min_delta = 0, patience = 5, verbose = 1, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c7d8ec0-05c8-4b73-924b-e055a5a7f181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.6705 - accuracy: 0.7698 - val_loss: 0.3193 - val_accuracy: 0.8573\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.2029 - accuracy: 0.9280 - val_loss: 0.1682 - val_accuracy: 0.9413\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.0688 - accuracy: 0.9800 - val_loss: 0.0963 - val_accuracy: 0.9773\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.0244 - accuracy: 0.9951 - val_loss: 0.0896 - val_accuracy: 0.9787\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.0047 - accuracy: 0.9996 - val_loss: 0.1002 - val_accuracy: 0.9827\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9813\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 5.6762e-04 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9813\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 3.4950e-04 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9800\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 96s 3s/step - loss: 2.4475e-04 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9827\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=64, epochs=20, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ddb69-028d-4019-9c26-37474f1dd331",
   "metadata": {},
   "source": [
    "As you can see above, the validation accuracy far exceeds a baseline of .50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f4c1c3c0-c66b-466f-a2c8-22f3f3a7a635",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 254, 254, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 125, 125, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 62, 62, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 246016)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                15745088  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 15,783,873\n",
      "Trainable params: 15,783,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9be87519-5cf6-439f-9f33-8eef339f0aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marka\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class = model.predict_classes(X_test)\n",
    "\n",
    "# confusion matrix \n",
    "cm=confusion_matrix(y_test,y_pred_class)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fe714-a8ca-4f54-965d-344b1f8798b6",
   "metadata": {},
   "source": [
    "## Processing Prediction (For Use in Streamlit App)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d9a06e05-60af-4590-97fa-78faa7af8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 pictures converted.\n"
     ]
    }
   ],
   "source": [
    "#Process Images for Preds\n",
    "\n",
    "pred_array = []\n",
    "\n",
    "pred_path = 'Data/pred/'\n",
    "\n",
    "#Convert images into arrays\n",
    "for file in os.listdir(pred_path):\n",
    "    try:\n",
    "#Resize all images for data homogeniety         \n",
    "        pred = load_img(pred_path + file, target_size=(256, 256))\n",
    "        pred_arr = img_to_array(pred) / 255\n",
    "        pred_array.append(pred_arr)\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "\n",
    "print(f'{len(pred_array)} pictures converted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a7046107-fd67-44e4-9afe-772539ab3506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(pred_array)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfc0b1ba-3b03-4baa-8604-81da89f71054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marka\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82e257-3907-45a8-a09d-6ec33758fbd7",
   "metadata": {},
   "source": [
    "## Saving and Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "092ff8ca-406e-4557-ac13-3bedc71d59ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
